Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 500
Job stats:
job               count    min threads    max threads
--------------  -------  -------------  -------------
Assembly              1              8              8
AssemblyConfig        1              1              1
FilteringReads        2              1              1
SortReads             2              1              1
all                   1              1              1
total                 7              1              8

Select jobs to execute...

[Tue Jun 20 16:11:39 2023]
rule SortReads:
    input: data/AM0909_2.fastq
    output: data/AM0909_2.sorted.fastq
    jobid: 6
    reason: Missing output files: data/AM0909_2.sorted.fastq
    wildcards: sample=AM0909, read=2
    resources: mem_mb=5000, disk_mb=16336, tmpdir=<TBD>, time=0-01:00:00, qos=standard


		module load bioawk
		bioawk -c fastx '{print}' data/AM0909_2.fastq | sort | awk -F'\t' '{print "@"$1;print $2;print "+"$1;print $3}' > data/AM0909_2.sorted.fastq
		
Submitted job 6 with external jobid 'Submitted batch job 13446577'.

[Tue Jun 20 16:11:39 2023]
rule AssemblyConfig:
    output: database/SeedDatabase/embplant_pt
    jobid: 2
    reason: Missing output files: database/SeedDatabase/embplant_pt
    wildcards: organelle_dbs=embplant_pt
    resources: mem_mb=10000, disk_mb=1000, tmpdir=<TBD>, time=0-01:00:00, qos=standard

RuleException in rule AssemblyConfig  in line 42 of /home/sjannalda/bgbm/projects/PlastidPipeline/workflow/Snakefile:
AttributeError: 'Params' object has no attribute 'database', when formatting the following:

		module load Bowtie2
		module load BLAST+
		mkdir -p {params.database}
		get_organelle_config.py -a {params.databases} --config-dir {params.database_folder}
		
